# Literature Review

This directory hosts the various papers deemed necessary and or useful to the project. The Project Literature Overview paper is a work in progress and will be expanded as research is continued.

## Another Larger Repository of Papers

https://github.com/WhileBug/AwesomeLLMJailBreakPapers

## Key Reference

### Safeguarding Large Language Models: A Survey
https://arxiv.org/abs/2406.02622

## Potential References

### JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks
https://arxiv.org/abs/2404.03027v4

### Revisiting Jailbreaking for Large Language Models: A Representation Engineering Perspective
https://aclanthology.org/2025.coling-main.212.pdf

### Not what youâ€™ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection
https://arxiv.org/abs/2302.12173

### BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
https://arxiv.org/abs/1810.04805v2

### Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities
https://arxiv.org/abs/2308.12833

### SMOOTHLLM: Defending Large Language Models Against Jailbreaking Attacks
https://arxiv.org/abs/2310.03684v4

### LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked
https://arxiv.org/abs/2308.07308v4

### Reflexion: Language Agents with Verbal Reinforcement Learning
https://arxiv.org/abs/2303.11366

### Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models
https://arxiv.org/abs/2310.04406

## Key Videos

### Learn to Implement Guardrails in Generative AI Applications
https://www.youtube.com/watch?v=XKDcOi-rZ_I

This video demonstrates how to implement simple guardrails using Guardrails AI.

Another useful source based from this video is the Guardrails AI GitHub page:

https://github.com/guardrails-ai/guardrails

### Guardrails Crash Course for Beginners
https://www.youtube.com/watch?v=XbriX2aYgqw

A YouTube tutorial detailing a small "crash course" for beginners on using NeMo Guardrails, Llama Guard, and Guardrails AI.

This video comes with an associated GitHub page that gives examples of usages:

https://github.com/AIAnytime/Guardrails-Crash-Course

### Build safe and reliable LLM applications with guardrails in this new course
https://www.youtube.com/watch?v=6mNnPISidlg

This video is an introduction to an online course, which is the more useful source:

https://www.deeplearning.ai/short-courses/safe-and-reliable-ai-via-guardrails/

### Reflection Agents by LangChain
https://www.youtube.com/watch?v=v5ymBTXNqtk

This video demonstrates the building and usage of multi-actor AI applications using the open-source framework LangGraph. It gives definitions of self-reflection, reflexion, and different types of implementation of these agentic systems.

Most importantly, it gives fundamental explanations behind the theory and gives real code examples, all of which is listed on thier GitHub:

https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/reflection/reflection.ipynb

https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/reflexion/reflexion.ipynb

https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/lats/lats.ipynb

There are also useful and inciteful papers mentioned in and associated with this video:

#### Reflexion: Language Agents with Verbal Reinforcement Learning
https://arxiv.org/abs/2303.11366

#### Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models
https://arxiv.org/abs/2310.04406

All of these are also listed above in the literature references.
